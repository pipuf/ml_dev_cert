{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pipuf/ml_dev_cert/blob/main/15_1_2_PRACTICE_MLP_for_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEEefa1ze1Ga"
      },
      "source": [
        "# Cifar-10 classification\n",
        "\n",
        "Cifar-10 is a dataset having 60000 color images with 32x32x3 pixels each one.\n",
        "\n",
        "Each image belongs to one out of 10 possible categories. Having exactly 6000 images per class.\n",
        "\n",
        "We have 50000 images for training and 10000 for testing.\n",
        "\n",
        "Let's use MLP models to solve this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkD6oIt5e1Gd"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Lshk1ee1Ge"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Keras will download it automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwO9KiSse1Gf",
        "outputId": "90487ba1-ad25-42bd-b7a3-f0459a5ffa20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('x_train shape: {}'.format(x_train.shape))\n",
        "print('x_test shape: {}'.format(x_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb_QxlMde1Gf"
      },
      "source": [
        "## [Complete] Plot some images for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfWOi4bKe1Gg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
        "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
        "\n",
        "\n",
        "# Initialize the scalers\n",
        "min_max_scaler = MinMaxScaler()\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# Apply MinMaxScaler\n",
        "x_train_minmax = min_max_scaler.fit_transform(x_train_flat)\n",
        "x_test_minmax = min_max_scaler.transform(x_test_flat)\n",
        "\n",
        "# Apply StandardScaler\n",
        "x_train_standard = standard_scaler.fit_transform(x_train_flat)\n",
        "x_test_standard = standard_scaler.transform(x_test_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y4b2Txxe1Gg"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "- Convert your data shape so you can use them with your MLP\n",
        "- Scale your images\n",
        "  - Try using MinMax and StandardScaler, compare both methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2GIF39_e1Gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c069ba-fb2b-4938-ce89-cdd2b963f3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped x_train: (50000, 3072)\n",
            "Reshaped x_test: (10000, 3072)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "x_train = np.random.rand(50000, 32, 32, 3)\n",
        "x_test = np.random.rand(10000, 32, 32, 3)\n",
        "\n",
        "# Reshape the data\n",
        "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
        "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
        "\n",
        "print(f\"Reshaped x_train: {x_train_flat.shape}\")\n",
        "print(f\"Reshaped x_test: {x_test_flat.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIi2BNJme1Gh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_jEEt1Ce1Gi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "953972f9-9460-48b6-fba0-ac1602e2763a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_and_evaluate() missing 4 required positional arguments: 'activation', 'weight_init', 'dropout_rate', and 'l2_reg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-619e7bfd6ea9>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0macc_minmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_minmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_minmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0macc_standard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_minmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_standard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: train_and_evaluate() missing 4 required positional arguments: 'activation', 'weight_init', 'dropout_rate', and 'l2_reg'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Define MLP model with various configurations\n",
        "def create_mlp_model(input_shape, layers_config, activation, weight_init, dropout_rate, l2_reg):\n",
        "    model = Sequential()\n",
        "    for i, units in enumerate(layers_config):\n",
        "        if i == 0:\n",
        "            model.add(Dense(units, activation=activation, kernel_initializer=weight_init, kernel_regularizer=l2(l2_reg), input_shape=input_shape))\n",
        "        else:\n",
        "            model.add(Dense(units, activation=activation, kernel_initializer=weight_init, kernel_regularizer=l2(l2_reg)))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training and evaluation function\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test, layers_config, activation, weight_init, dropout_rate, l2_reg):\n",
        "    input_shape = (x_train.shape[1],)\n",
        "    model = create_mlp_model(input_shape, layers_config, activation, weight_init, dropout_rate, l2_reg)\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), verbose=1)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "    return test_acc\n",
        "\n",
        "# Different configurations to test\n",
        "configs = [\n",
        "    {'layers': [128, 64], 'activation': 'relu', 'weight_init': 'he_normal', 'dropout_rate': 0.5, 'l2_reg': 1e-4},\n",
        "    {'layers': [256, 128, 64], 'activation': 'tanh', 'weight_init': 'glorot_uniform', 'dropout_rate': 0.3, 'l2_reg': 1e-3},\n",
        "    {'layers': [512, 256], 'activation': 'relu', 'weight_init': 'he_uniform', 'dropout_rate': 0.4, 'l2_reg': 1e-2},\n",
        "    {'layers': [128, 128, 128], 'activation': 'sigmoid', 'weight_init': 'glorot_normal', 'dropout_rate': 0.2, 'l2_reg': 1e-5}\n",
        "]\n",
        "\n",
        "# Evaluate all configurations on both scaling methods\n",
        "results = []\n",
        "for config in configs:\n",
        "    acc_minmax = train_and_evaluate(x_train_minmax, y_train, x_test_minmax, y_test, config)\n",
        "    acc_standard = train_and_evaluate(x_train_standard, y_train, x_test_standard, y_test, config)\n",
        "    results.append((config, acc_minmax, acc_standard))\n",
        "\n",
        "# Print results\n",
        "for config, acc_minmax, acc_standard in results:\n",
        "    print(f\"Config: {config}\")\n",
        "    print(f\"MinMax Scaler Accuracy: {acc_minmax}\")\n",
        "    print(f\"Standard Scaler Accuracy: {acc_standard}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Use keras tuner to find the best hyperparameters\n"
      ],
      "metadata": {
        "id": "5K6DYEt6jgjN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCT7YClAjfaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "\n",
        "Use different evaluation metrics and your testing dataset to report how good your model is.\n",
        "\n",
        "Think using scikit-learn `classification_report` and confussion matrix to generate good quality reports.\n"
      ],
      "metadata": {
        "id": "4KfS02qfjowv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1nEhurUjoNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}